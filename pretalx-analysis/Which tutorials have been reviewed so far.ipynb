{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2304a0a0-bc33-4569-a081-085214082871",
   "metadata": {},
   "source": [
    "# Finding which tutorials have been reviewed so far"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215fa6d9-d537-40be-8b2d-793e12efbc70",
   "metadata": {},
   "source": [
    "This notebook fetches submissions and reviews from the SciPy PreTalx database,\n",
    "in order to perform some simple data exploration.\n",
    "In particular, we look towards determining which of all submissions are tutorials,\n",
    "and of these, which have been reviewed.\n",
    "\n",
    "Before running this notebook, be sure to [have set up](README.md#setup) the necessary computing environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c61b0-2618-4b9d-a5c3-d1c0cb58f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import closing\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583aff02-a5ef-42b6-974e-28bda92c1de8",
   "metadata": {},
   "source": [
    "<center style=\"padding-top: 3em; padding-bottom: 3em;\">\n",
    "    <strong style=\"border: 1px solid; padding: 6pt;\">Important: change the next cell so it contains <em>your</em> PreTalx authentication token.</strong>\n",
    "</center>\n",
    "\n",
    "You can find your API token on your [profile page](https://cfp.scipy.org/orga/me) on PreTalx, under the **API Access** heading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1fce5b-1f9f-4b39-a9b9-58a4b8512224",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = \"This is *my* token and I don't know you\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8668e689-5c11-46a5-9c17-33b9dc76ab54",
   "metadata": {},
   "source": [
    "The PreTalx API provides the submissions and reviews in paged streams of results.\n",
    "Each page provides up to 25 results out of the lot.\n",
    "The following function articulates the string of requests to download all items of a certain stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3329dc91-2182-4ffe-8e0e-d48d8af56826",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sequence_cfp_scipy(url1, max_queries=50):\n",
    "    sequence = []\n",
    "    url = url1\n",
    "    max_queries = 50\n",
    "    num_queries = 0\n",
    "    num_results_expected = None\n",
    "\n",
    "    with closing(tqdm(total=max_queries)) as progress:\n",
    "        while True:\n",
    "            response = rq.get(url, headers={\"Authorization\": f\"Token {TOKEN}\"})\n",
    "            assert response.ok\n",
    "            data = response.json()\n",
    "            progress.update()\n",
    "            num_queries += 1\n",
    "\n",
    "            assert \"results\" in data\n",
    "            assert \"next\" in data\n",
    "\n",
    "            if num_results_expected is None and \"count\" in data:\n",
    "                num_results_expected = data[\"count\"]\n",
    "                max_queries = int(np.ceil(num_results_expected / len(data[\"results\"])))\n",
    "                progress.reset(max_queries)\n",
    "                progress.update(num_queries)\n",
    "            else:\n",
    "                assert num_results_expected == data[\"count\"]\n",
    "\n",
    "            sequence += data[\"results\"]\n",
    "            url = data[\"next\"]\n",
    "            if not url:\n",
    "                break\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f483c1-3eed-43c8-a9d0-331b32e77b4c",
   "metadata": {},
   "source": [
    "Let's fetch the raw submissions and reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee69d00-b99b-4224-8244-232ef607eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_ = fetch_sequence_cfp_scipy(\"https://cfp.scipy.org/api/events/2024/submissions/\")\n",
    "len(submissions_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a781ba-db7b-4ed4-8ffa-9d8cd5fc2727",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_ = fetch_sequence_cfp_scipy(\"https://cfp.scipy.org/api/events/2024/reviews/\")\n",
    "len(reviews_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c270c7-954e-41f8-91e8-d1303d0d265b",
   "metadata": {},
   "source": [
    "Help me, Pandas. You're my only hope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09d9f58-b396-43b4-8869-804bf73f333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions = pd.DataFrame.from_records(submissions_)\n",
    "submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cdc891f-3fdd-4785-8ec6-dcfca30e3f00",
   "metadata": {},
   "source": [
    "The data is not flat.\n",
    "At a glance, I see that talk submissions have the clean `Talk` type (`submission_type`), but others have a localizable structure.\n",
    "I should think that all of these dictionaries should have the form `{'en': some_type}`, but let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44223bc1-1ccf-4535-af83-03c8664ad291",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions[\"submission_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca445b-c88f-41a9-8215-59141a8f5ccf",
   "metadata": {},
   "source": [
    "The assumption is valid,\n",
    "so let's flatten the `submission_type` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bd706a-e282-4bdf-a822-e4c51b3e6334",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions[\"submission_type\"] = submissions[\"submission_type\"].apply(lambda x: x[\"en\"] if isinstance(x, dict) else x)\n",
    "submissions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537ec7dd-d81a-429a-b968-c2229a921898",
   "metadata": {},
   "source": [
    "This makes it easy to extract the tutorials out of the whole set of submissions.\n",
    "Glancing further, I see that some submissions have already been rejected.\n",
    "Take a look at the set of submission states to determine which to retain in further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20eeba1f-53e0-4130-bacf-145332d59823",
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions[\"state\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6acded-323c-4b56-8e70-ff1c73fa7925",
   "metadata": {},
   "source": [
    "So I presume to care only about tutorials in the `submitted` state with respect to worrying as to whether they have been reviewed.\n",
    "Let's filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af96df-cd86-4f5b-b412-81f14d4d09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorials = submissions.loc[(submissions[\"submission_type\"] == \"Tutorial\") & (submissions[\"state\"] == \"submitted\")].copy()\n",
    "tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821416b8-c1e3-4de2-b75d-f10372a05328",
   "metadata": {},
   "source": [
    "As I'm going to list submissions in junction with reviews,\n",
    "I care about eyeballing the title and author list of each tutorial.\n",
    "The latter are in readable form, but the former is not.\n",
    "Let's unpack author list and represent them similar to how they often are typographed as paper citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f46cfc1-1789-4c8f-b817-fe4cad96261d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_authors(speakers):\n",
    "    surnames = [speaker.get(\"name\", \"WHO\").split()[-1] for speaker in speakers]\n",
    "    assert len(surnames) > 0\n",
    "    if len(surnames) >= 4:\n",
    "        return f\"{surnames[0]} et al.\"\n",
    "    elif len(surnames) == 3:\n",
    "        return f\"{surnames[0]}, {surnames[1]} and {surnames[2]}\"\n",
    "    elif len(surnames) == 2:\n",
    "        return f\"{surnames[0]} and {surnames[1]}\"\n",
    "    else:\n",
    "        return surnames[0]\n",
    "\n",
    "tutorials[\"authors\"] = tutorials[\"speakers\"].apply(label_authors)\n",
    "tutorials"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff3197-24ef-484b-b97d-7ad4dfd2094e",
   "metadata": {},
   "source": [
    "Ok,\n",
    "having what I need to track tutorials,\n",
    "let's Pandasify reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d853b66-4fb1-4297-86dc-644707d0b3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.DataFrame.from_records(reviews_)\n",
    "reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54704a-a594-4535-9089-6208c5bc3cc4",
   "metadata": {},
   "source": [
    "Tracking which tutorials are targeted by which review is a simple join.\n",
    "We can use the unique submission identifiers as join key:\n",
    "column `code` in the `tutorials` frame,\n",
    "column `submission` in the `reviews` frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5234930-ef79-4ad4-988f-94a6395396cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorials_reviewed = (\n",
    "    tutorials[[\"code\", \"authors\", \"title\"]].merge(\n",
    "        reviews[[\"submission\", \"user\", \"updated\", \"score\"]],\n",
    "        how=\"left\",\n",
    "        left_on=\"code\",\n",
    "        right_on=\"submission\"\n",
    "    )\n",
    "    .drop(columns=[\"submission\"])\n",
    "    .astype({\"updated\": \"datetime64[ns, GMT]\"})\n",
    ")\n",
    "tutorials_reviewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9442d260-9b6a-46f1-aebd-a21615242921",
   "metadata": {},
   "source": [
    "Joins are tricky, so let's sanity check that the data frame above effectively stores data on each retained tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf864d62-165a-4f1a-aca1-ee0bb218bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert tutorials_reviewed[\"code\"].nunique() == tutorials[\"code\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c0abe-0ea1-427c-a8b9-f8f2e555f68d",
   "metadata": {},
   "source": [
    "Which tutorials have not been reviewed yet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef0585-407a-4da6-bf1b-2fb93720f126",
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorials_reviewed.loc[tutorials_reviewed[\"updated\"].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f02e63-60f0-4df3-b2b0-0a4a754fbdf0",
   "metadata": {},
   "source": [
    "Of those that _were_ reviewed, which got less than 2 reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6d5a0-b59a-42e3-9ee5-5ccf0e01a7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_reviews =(\n",
    "    tutorials_reviewed\n",
    "    .dropna(how=\"any\")\n",
    "    .groupby([\"code\", \"authors\", \"title\"], as_index=False)\n",
    "    .size()\n",
    "    .sort_values(\"size\")\n",
    ")\n",
    "num_reviews.loc[num_reviews[\"size\"] < 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
